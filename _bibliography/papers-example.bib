---
---

@inproceedings{wu2024vertibench,
selected={true},
bibtex_show={true},

title={VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks},
author={Zhaomin Wu and Junyi Hou and Bingsheng He},
booktitle={The Twelfth International Conference on Learning Representations},
abbr={ICLR 2024},
year={2024},
url={https://openreview.net/forum?id=glwwbaeKm2}
}

@article{10.1145/3589313,
selected={true},
bibtex_show={true},

author = {Wu, Zhaomin and Zhu, Junhui and Li, Qinbin and He, Bingsheng},
title = {DeltaBoost: Gradient Boosting Decision Trees with Efficient Machine Unlearning},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3589313},
doi = {10.1145/3589313},
journal = {Proc. ACM Manag. Data},
abbr = {SIGMOD 2023},
month = {jun},
articleno = {168},
numpages = {26},
keywords = {data deletion, gradient boosting decision trees, machine unlearning},
}

@inproceedings{MLSYS2023_3430e705,
 bibtex_show={true},

 author = {Li, Qinbin and ZHAOMIN, WU and Cai, Yanzheng and han, yuxuan and Yung, Ching Man and Fu, Tianyuan and He, Bingsheng},
 booktitle = {Proceedings of Machine Learning and Systems},
 abbr = {MLSys 2023},
 editor = {D. Song and M. Carbin and T. Chen},
 pages = {89--103},
 publisher = {Curan},
 title = {FedTree: A Federated Learning System For Trees},
 url = {https://proceedings.mlsys.org/paper_files/paper/2023/file/3430e7055936cb8e26451ed49fce84a6-Paper-mlsys2023.pdf},
 volume = {5},
 year = {2023}
}

@inproceedings{NEURIPS2022_84b74416,
 selected={true},
 bibtex_show={true},

 author = {Wu, Zhaomin and Li, Qinbin and He, Bingsheng},
 booktitle = {Advances in Neural Information Processing Systems},
 abbr={NeurIPS 2022},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {21087--21100},
 publisher = {Curran Associates, Inc.},
 title = {A Coupled Design of Exploiting Record Similarity for Practical Vertical Federated Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/84b744165a0597360caad96b06e69313-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@ARTICLE {9789268,
selected={true},
bibtex_show={true},

author = {Z. Wu and Q. Li and B. He},
journal = {IEEE Transactions on Big Data},
abbr = {TBD 2022},
title = {Practical Vertical Federated Learning with Unsupervised Representation Learning},
year = {2022},
volume = {},
number = {01},
issn = {2332-7790},
pages = {1-1},
abstract = {As societal concerns on data privacy recently increase, we have witnessed data silos among multiple parties in various applications. Federated learning emerges as a new learning paradigm that enables multiple parties to collaboratively train a machine learning model without sharing their raw data. Vertical federated learning, where each party owns different features of the same set of samples and only a single party has the label, is an important and challenging topic in federated learning. Communication costs among different parties have been a major hurdle for practical vertical learning systems. In this paper, we propose a novel communication-efficient vertical federated learning algorithm named FedOnce, which requires only one-shot communication among parties. To improve model accuracy and provide privacy guarantee, FedOnce features unsupervised learning representations in the federated setting and privacy-preserving techniques based on moments accountant. The comprehensive experiments on 10 datasets demonstrate that FedOnce achieves close performance compared to state-of-the-art vertical federated learning algorithms with much lower communication costs. Meanwhile, our privacy-preserving technique significantly outperforms the state-of-the-art approaches under the same privacy budget.},
keywords = {collaborative work;privacy;differential privacy;training;data privacy;costs;unsupervised learning},
doi = {10.1109/TBDATA.2022.3180117},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}


@article{10.1145/3510540,
bibtex_show={true},

author = {Hu, Sixu and Li, Yuan and Liu, Xu and Li, Qinbin and Wu, Zhaomin and He, Bingsheng},
title = {The OARF Benchmark Suite: Characterization and Implications for Federated Learning Systems},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3510540},
doi = {10.1145/3510540},
abstract = {This article presents and characterizes an Open Application Repository for Federated Learning (OARF), a benchmark suite for federated machine learning systems. Previously available benchmarks for federated learning (FL) have focused mainly on synthetic datasets and use a limited number of applications. OARF mimics more realistic application scenarios with publicly available datasets as different data silos in image, text, and structured data. Our characterization shows that the benchmark suite is diverse in data size, distribution, feature distribution, and learning task complexity. The extensive evaluations with reference implementations show the future research opportunities for important aspects of FL systems. We have developed reference implementations, and evaluated the important aspects of FL, including model accuracy, communication cost, throughput, and convergence time. Through these evaluations, we discovered some interesting findings such as FL can effectively increase end-to-end throughput. The code of OARF is publicly available on GitHub.1},
journal = {ACM Trans. Intell. Syst. Technol.},
abbr = {TIST 2022},
month = {jun},
articleno = {63},
numpages = {32},
keywords = {framework, dataset, benchmark, machine learning, Federated learning}
}

@inproceedings{DBLP:conf/aaai/LiWWH20,
 bibtex_show={true},
  author       = {Qinbin Li and
                  Zhaomin Wu and
                  Zeyi Wen and
                  Bingsheng He},
  title        = {Privacy-Preserving Gradient Boosting Decision Trees},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  abbr = {AAAI 2020},
  pages        = {784--791},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i01.5422},
  doi          = {10.1609/AAAI.V34I01.5422},
  timestamp    = {Sat, 30 Sep 2023 09:33:11 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/LiWWH20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE {9599369,
bibtex_show={true},

author = {Q. Li and Z. Wen and Z. Wu and S. Hu and N. Wang and Y. Li and X. Liu and B. He},
journal = {IEEE Transactions on Knowledge &amp; Data Engineering},
abbr = {TKDE 2023},
title = {A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection},
year = {2023},
volume = {35},
number = {04},
issn = {1558-2191},
pages = {3347-3366},
abstract = {As data privacy increasingly becomes a critical societal concern, federated learning has been a hot research topic in enabling the collaborative training of machine learning models among different organizations under the privacy restrictions. As researchers try to support more machine learning models with different privacy-preserving approaches, there is a requirement in developing systems and infrastructures to ease the development of various federated learning algorithms. Similar to deep learning systems such as PyTorch and TensorFlow that boost the development of deep learning, federated learning systems (FLSs) are equivalently important, and face challenges from various aspects such as effectiveness, efficiency, and privacy. In this survey, we conduct a comprehensive review on federated learning systems. To understand the key design system components and guide future research, we introduce the definition of federated learning systems and analyze the system components. Moreover, we provide a thorough categorization for federated learning systems according to six different aspects, including data distribution, machine learning model, privacy mechanism, communication architecture, scale of federation and motivation of federation. The categorization can help the design of federated learning systems as shown in our case studies. By systematically summarizing the existing federated learning systems, we present the design factors, case studies, and future research opportunities.},
keywords = {collaborative work;data models;machine learning;data privacy;computational modeling;deep learning;servers},
doi = {10.1109/TKDE.2021.3124599},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {apr}
}


@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  selected={false}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schr√∂dinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
